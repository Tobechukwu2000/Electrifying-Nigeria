{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Models: ANN, ELM, SVR, KRR, RF, XGB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from skelm import ELMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_excel(\"Data No Storage.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fixed_randomization(data):\n",
    "    np.random.seed(42) \n",
    "    rand_data = data.sample(frac=1).reset_index(drop=True)\n",
    "    return rand_data\n",
    "\n",
    "rand_data = fixed_randomization(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_unscale = rand_data[rand_data.columns[0:6]]\n",
    "Y_data_unscale = rand_data[rand_data.columns[6:11]]\n",
    "\n",
    "Y_data = Y_data_unscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "MMS = MinMaxScaler()\n",
    "X_data = SS.fit_transform(X_data_unscale)\n",
    "X_data = pd.DataFrame(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_data = Y_data[Y_data.columns[0:1]]\n",
    "y2_data = Y_data[Y_data.columns[1:2]]\n",
    "y3_data = Y_data[Y_data.columns[2:3]]\n",
    "y4_data = Y_data[Y_data.columns[3:4]]\n",
    "y5_data = Y_data[Y_data.columns[4:5]]\n",
    "\n",
    "\n",
    "y1_train = Y_train[Y_train.columns[0:1]]\n",
    "y2_train = Y_train[Y_train.columns[1:2]]\n",
    "y3_train = Y_train[Y_train.columns[2:3]]\n",
    "y4_train = Y_train[Y_train.columns[3:4]]\n",
    "y5_train = Y_train[Y_train.columns[4:5]]\n",
    "\n",
    "\n",
    "y1_test = Y_test[Y_test.columns[0:1]]\n",
    "y2_test = Y_test[Y_test.columns[1:2]]\n",
    "y3_test = Y_test[Y_test.columns[2:3]]\n",
    "y4_test = Y_test[Y_test.columns[3:4]]\n",
    "y5_test = Y_test[Y_test.columns[4:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Extract values from DataFrames\n",
    "    y_true_values = y_true.values.flatten()\n",
    "    y_pred_values = y_pred.values.flatten()\n",
    "    \n",
    "    # R2 score\n",
    "    r2 = r2_score(y_true_values, y_pred_values)\n",
    "    r2 = round(r2, 4)\n",
    "    \n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_true_values, y_pred_values)\n",
    "    mse = round(mse, 4)\n",
    "    \n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse = round(rmse, 4)\n",
    "\n",
    "    # Average Absolute Deviation (AAD)\n",
    "    aad = np.mean(np.abs(y_true_values - y_pred_values))\n",
    "    aad = round(aad, 4)\n",
    "    \n",
    "    # Squared Error Percentage (SEP)\n",
    "    sep = np.mean(((y_true_values - y_pred_values) / y_true_values)**2) * 100\n",
    "    sep = round(sep, 4)\n",
    "    \n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_true_values, y_pred_values)\n",
    "    mae = round(mae, 4)\n",
    "    \n",
    "    '''print('r2: ', r2)\n",
    "    print('mse: ', mse)\n",
    "    print('rmse: ', rmse)\n",
    "    print('aad: ', aad)\n",
    "    print('sep: ', sep)\n",
    "    print('mae: ', mae)'''   \n",
    "\n",
    "    print(r2)\n",
    "    print(mse)\n",
    "    print(rmse)\n",
    "    print(aad)\n",
    "    print(sep)\n",
    "    print(mae) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 0.000001, 1000000),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-6, 1e+1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf']),\n",
    "        'degree': trial.suggest_int('degree', 1, 5),\n",
    "        'gamma': trial.suggest_float('gamma', 0.00001, 0.1)\n",
    "    }\n",
    "\n",
    "    model = SVR(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)\n",
    "\n",
    "# Print the best trial\n",
    "print('Best trial', study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_y1 = study.best_params\n",
    "\n",
    "svr_model_y1 = SVR(**svr_param_y1)\n",
    "svr_model_y1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svr_model_y1.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = svr_model_y1.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = svr_model_y1.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 0.000001, 1000000),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-6, 1e+1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf']),\n",
    "        'degree': trial.suggest_int('degree', 1, 5),\n",
    "        'gamma': trial.suggest_float('gamma', 0.00001, 0.1)\n",
    "    }\n",
    "\n",
    "    model = SVR(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_y2 = study.best_params\n",
    "\n",
    "svr_model_y2 = SVR(**svr_param_y2)\n",
    "svr_model_y2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svr_model_y2.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = svr_model_y2.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = svr_model_y2.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 0.000001, 1000000),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-6, 1e+1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf', 'linear']),\n",
    "        'degree': trial.suggest_int('degree', 1, 5),\n",
    "        'gamma': trial.suggest_float('gamma', 0.00001, 0.1)\n",
    "    }\n",
    "\n",
    "    model = SVR(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_y3 = study.best_params\n",
    "\n",
    "svr_model_y3 = SVR(**svr_param_y3)\n",
    "svr_model_y3.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svr_model_y3.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = svr_model_y3.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = svr_model_y3.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 0.000001, 1000000),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-6, 1e+1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf']),\n",
    "        'degree': trial.suggest_int('degree', 1, 5),\n",
    "        'gamma': trial.suggest_float('gamma', 0.00001, 0.1)\n",
    "    }\n",
    "\n",
    "    model = SVR(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_y4 = study.best_params\n",
    "\n",
    "svr_model_y4 = SVR(**svr_param_y4)\n",
    "svr_model_y4.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svr_model_y4.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = svr_model_y4.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = svr_model_y4.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 1000)\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_y1 = study.best_params\n",
    "\n",
    "xgb_model_y1 = XGBRegressor(**xgb_params_y1)\n",
    "xgb_model_y1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgb_model_y1.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = xgb_model_y1.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = xgb_model_y1.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 1000)\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_y2 = study.best_params\n",
    "\n",
    "xgb_model_y2 = XGBRegressor(**xgb_params_y2)\n",
    "xgb_model_y2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgb_model_y2.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = xgb_model_y2.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = xgb_model_y2.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 1000)\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_y3 = study.best_params\n",
    "\n",
    "xgb_model_y3 = XGBRegressor(**xgb_params_y3)\n",
    "xgb_model_y3.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgb_model_y3.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = xgb_model_y3.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = xgb_model_y3.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 1000)\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_y4 = study.best_params\n",
    "\n",
    "xgb_model_y4 = XGBRegressor(**xgb_params_y4)\n",
    "xgb_model_y4.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgb_model_y4.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = xgb_model_y4.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = xgb_model_y4.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)\n",
    "\n",
    "y_data_pred = pd.DataFrame(y_data_pred)\n",
    "y_data = pd.DataFrame(y_data)\n",
    "calculate_metrics(y_data, y_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "# Define the number of layers in the model\n",
    "n_layers = 4\n",
    "\n",
    "def objective(trial):\n",
    "    # Initialize an empty list to store layer sizes\n",
    "    layer_sizes = []\n",
    "    \n",
    "    # Add layer sizes to the list based on the number of layers\n",
    "    for i in range(n_layers):\n",
    "        layer_sizes.append(trial.suggest_int(f'layer_size_{i}', 1, 50))\n",
    "    \n",
    "    param = {\n",
    "        'hidden_layer_sizes': tuple(layer_sizes),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 100),\n",
    "        'alpha': trial.suggest_float('alpha', 0.00001, 1),\n",
    "    }\n",
    "    model = MLPRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "# Define the number of layers in the model\n",
    "n_layers = 4\n",
    "\n",
    "def objective(trial):\n",
    "    # Initialize an empty list to store layer sizes\n",
    "    layer_sizes = []\n",
    "    \n",
    "    # Add layer sizes to the list based on the number of layers\n",
    "    for i in range(n_layers):\n",
    "        layer_sizes.append(trial.suggest_int(f'layer_size_{i}', 1, 50))\n",
    "    \n",
    "    param = {\n",
    "        'hidden_layer_sizes': tuple(layer_sizes),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 100),\n",
    "        'alpha': trial.suggest_float('alpha', 0.00001, 1),\n",
    "    }\n",
    "    model = MLPRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_y1 = MLPRegressor(hidden_layer_sizes=(8, 30, 50, 32), activation='relu', alpha=0.13762346635059558, solver='lbfgs', random_state=3)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ann_model_y1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ann_model_y1.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = ann_model_y1.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = ann_model_y1.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "\n",
    "# Define the number of layers in the model\n",
    "n_layers = 4\n",
    "\n",
    "def objective(trial):\n",
    "    # Initialize an empty list to store layer sizes\n",
    "    layer_sizes = []\n",
    "    \n",
    "    # Add layer sizes to the list based on the number of layers\n",
    "    for i in range(n_layers):\n",
    "        layer_sizes.append(trial.suggest_int(f'layer_size_{i}', 1, 50))\n",
    "    \n",
    "    param = {\n",
    "        'hidden_layer_sizes': tuple(layer_sizes),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 100),\n",
    "        'alpha': trial.suggest_float('alpha', 0.00001, 1),\n",
    "    }\n",
    "    model = MLPRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_y2 = MLPRegressor(hidden_layer_sizes=(40, 36, 17, 3), activation='relu', alpha=0.421732762333308, solver='lbfgs', random_state=34)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ann_model_y2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ann_model_y2.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = ann_model_y2.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = ann_model_y2.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "\n",
    "# Define the number of layers in the model\n",
    "n_layers = 4\n",
    "\n",
    "def objective(trial):\n",
    "    # Initialize an empty list to store layer sizes\n",
    "    layer_sizes = []\n",
    "    \n",
    "    # Add layer sizes to the list based on the number of layers\n",
    "    for i in range(n_layers):\n",
    "        layer_sizes.append(trial.suggest_int(f'layer_size_{i}', 1, 50))\n",
    "    \n",
    "    param = {\n",
    "        'hidden_layer_sizes': tuple(layer_sizes),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 100),\n",
    "        'alpha': trial.suggest_float('alpha', 0.00001, 1),\n",
    "    }\n",
    "    model = MLPRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_y3 = MLPRegressor(hidden_layer_sizes=(38, 20, 2, 36), activation='relu', alpha=0.1368361449397597, solver='lbfgs', random_state=100)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ann_model_y3.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ann_model_y3.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = ann_model_y3.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = ann_model_y3.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "\n",
    "# Define the number of layers in the model\n",
    "n_layers = 4\n",
    "\n",
    "def objective(trial):\n",
    "    # Initialize an empty list to store layer sizes\n",
    "    layer_sizes = []\n",
    "    \n",
    "    # Add layer sizes to the list based on the number of layers\n",
    "    for i in range(n_layers):\n",
    "        layer_sizes.append(trial.suggest_int(f'layer_size_{i}', 1, 50))\n",
    "    \n",
    "    param = {\n",
    "        'hidden_layer_sizes': tuple(layer_sizes),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 100),\n",
    "        'alpha': trial.suggest_float('alpha', 0.00001, 1),\n",
    "    }\n",
    "    model = MLPRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction='maximize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters', study.best_params)\n",
    "\n",
    "# Print the best value\n",
    "print('Best value', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_y4 = MLPRegressor(hidden_layer_sizes=(33, 10, 8, 40), activation='relu', alpha=0.20068666427656182, solver='lbfgs', random_state=52)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ann_model_y4.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ann_model_y4.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "y_pred = ann_model_y4.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_data_pred = ann_model_y4.predict(X_data)\n",
    "data_r2 = r2_score(y_data, y_data_pred)\n",
    "\n",
    "print('Train R_sq:', train_r2)\n",
    "print('Test R_sq:', test_r2)\n",
    "print('Data R_sq:', data_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "# Model for y1\n",
    "y1_params = {'C': 792455.0628709563, 'epsilon': 1.615158320784387, 'kernel': 'rbf', 'degree': 4, 'gamma': 0.018028712570561923}\n",
    "model_y1 = SVR(**y1_params)\n",
    "model_y1.fit(X_train, y_train)\n",
    "y1_pred = model_y1.predict(X_test)\n",
    "\n",
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "# Model for y2\n",
    "y2_params = {'C': 35529.565119700674, 'epsilon': 0.01398121990100254, 'kernel': 'rbf', 'degree': 4, 'gamma': 0.00759513082892152}\n",
    "model_y2 = SVR(**y2_params)\n",
    "model_y2.fit(X_train, y_train)\n",
    "y2_pred = model_y2.predict(X_test)\n",
    "\n",
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "# Model for y3\n",
    "y3_params = {'C': 741046.8928371427, 'epsilon': 0.010895466956371502, 'kernel': 'rbf', 'degree': 5, 'gamma': 0.009751068786055191}\n",
    "model_y3 = SVR(**y3_params)\n",
    "model_y3.fit(X_train, y_train)\n",
    "y3_pred = model_y3.predict(X_test)\n",
    "\n",
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "# Model for y4\n",
    "model_y4 = MLPRegressor(hidden_layer_sizes=(33, 10, 8, 40), activation='relu', alpha=0.20068666427656182, solver='lbfgs', random_state=52)\n",
    "model_y4.fit(X_train, y_train)\n",
    "y4_pred = model_y4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copy column names from df_source to df_target\n",
    "X_data.columns = X_data_unscale.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your list\n",
    "mm = [1.11956119, -0.0427942,   0.02750056, -0.72244753,  0.13830575, -1.15761651]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(mm)\n",
    "df = df.T\n",
    "df.columns = X_data_unscale.columns\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "\n",
    "y1_params = {'C': 792455.0628709563, 'epsilon': 1.615158320784387, 'kernel': 'rbf', 'degree': 4, 'gamma': 0.018028712570561923}\n",
    "model_y1 = SVR(**y1_params)\n",
    "model_y1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.KernelExplainer(model_y1.predict, X_train)\n",
    "shap_values = explainer(df)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.waterfall(shap_values[0], max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y1_data\n",
    "y_train = y1_train\n",
    "y_test = y1_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "\n",
    "mod_1 = {'max_depth': 3, 'learning_rate': 0.6559938747200145, 'n_estimators': 742, 'min_child_weight': 5, 'gamma': 0.2364570538403641, 'subsample': 0.9166005202188677, 'colsample_bytree': 0.5467984466797525, 'reg_alpha': 0.34210178318639684, 'reg_lambda': 0.6058891382532333, 'random_state': 590}\n",
    "\n",
    "model_y1 = XGBRegressor(**mod_1)\n",
    "model_y1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.Explainer(model_y1, X_train)\n",
    "shap_values = explainer(X_data)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "\n",
    "y2_params = {'C': 35529.565119700674, 'epsilon': 0.01398121990100254, 'kernel': 'rbf', 'degree': 4, 'gamma': 0.00759513082892152}\n",
    "model_y2 = SVR(**y2_params)\n",
    "model_y2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.KernelExplainer(model_y2.predict, X_data)\n",
    "shap_values = explainer(df)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.waterfall(shap_values[0], max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y2_data\n",
    "y_train = y2_train\n",
    "y_test = y2_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "mod_2 = {'max_depth': 8, 'learning_rate': 0.8058929837921041, 'n_estimators': 707, 'min_child_weight': 6, 'gamma': 0.6203690244688376, 'subsample': 0.8633675242642986, 'colsample_bytree': 0.351803542599373, 'reg_alpha': 0.38202482253134534, 'reg_lambda': 0.19326434501771286, 'random_state': 507}\n",
    "\n",
    "model_y2 = XGBRegressor(**mod_2)\n",
    "model_y2.fit(X_train, y_train)\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.Explainer(model_y2, X_data)\n",
    "shap_values = explainer(X_data)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "\n",
    "# Import necessary libraries\n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "# Define the parameters for the XGBRegressor\n",
    "y3_params = {'C': 741046.8928371427, 'epsilon': 0.010895466956371502, 'kernel': 'rbf', 'degree': 5, 'gamma': 0.009751068786055191}\n",
    "model_y3 = SVR(**y3_params)\n",
    "model_y3.fit(X_data, y_data)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.KernelExplainer(model_y3.predict, X_data)\n",
    "shap_values = explainer(df)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.waterfall(shap_values[0], max_display=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y3_data\n",
    "y_train = y3_train\n",
    "y_test = y3_test\n",
    "\n",
    "# Import necessary libraries\n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "# Define the parameters for the XGBRegressor\n",
    "y3_params = {'max_depth': 3, 'learning_rate': 0.5560764434875813, 'n_estimators': 581, 'min_child_weight': 1, 'gamma': 0.17663683708839756, 'subsample': 0.22400187438994715, 'colsample_bytree': 0.45123077147598545, 'reg_alpha': 0.8358287950607348, 'reg_lambda': 0.3030245049556971, 'random_state': 475}\n",
    "\n",
    "# Fit the model\n",
    "model_y3 = XGBRegressor(**y3_params)\n",
    "model_y3.fit(X_data, y_data)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.Explainer(model_y3, X_data)\n",
    "shap_values = explainer(X_data)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "\n",
    "model_y4 = MLPRegressor(hidden_layer_sizes=(33, 10, 8, 40), activation='relu', alpha=0.20068666427656182, solver='lbfgs', random_state=52)\n",
    "model_y4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.KernelExplainer(model_y4.predict, X_train)\n",
    "shap_values = explainer(df)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.waterfall(shap_values[0], max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_data = y4_data\n",
    "y_train = y4_train\n",
    "y_test = y4_test\n",
    "\n",
    "# Ensure X_data is a DataFrame with proper feature names\n",
    "if not isinstance(X_data, pd.DataFrame):\n",
    "    X_data = pd.DataFrame(X_data)\n",
    "\n",
    "# Convert feature names to strings if they are not already\n",
    "X_data.columns = [str(col) for col in X_data.columns]\n",
    "\n",
    "\n",
    "mod_4 = {'max_depth': 10, 'learning_rate': 0.43666973070690324, 'n_estimators': 828, 'min_child_weight': 8, 'gamma': 0.28078926083310424, 'subsample': 0.6681118230081214, 'colsample_bytree': 0.4876447096098242, 'reg_alpha': 0.29034765465801493, 'reg_lambda': 0.3669174369705459, 'random_state': 949}\n",
    "\n",
    "model_y4 = XGBRegressor(**mod_4)\n",
    "model_y4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.Explainer(model_y4, X_data)\n",
    "shap_values = explainer(X_data)\n",
    "\n",
    "# Plot the SHAP values using a waterfall plot\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
